# 大数据日知录-架构与算法（一）

## Intro
**声明：本系列文档为本人学习《大数据日知录 架构与算法》（张俊林著 电子工业出版社 2014年9月第一版）的内容提纲。**  
我幻想我有这样一个技能包，我在里面放了一些马上可以拿出来使用的技能，也放了一些技能的索引和说明，当我需要的时候我能想起它并且能快速找到它让其为我所用。


## 第0章 当谈论大数据时我们在谈什么
1.大数据处理的目标：从海量异质数据中挖掘知识。包含了数据源收集、数据存储管理、数据分析与挖掘以及数据展现与获取等。

## 第1章 数据分片与路由
1.纵向扩展：传统并行数据库系统为了获取更好的性能，通过改善单机硬件资源；  

2.横向扩展：目前主流的大数据存储与计算系统通过增加机器来获得水平扩展能力；  

3.数据分片是指在大数据存储中，将海量的数据切分然后分配到各个机器中去，而数据路由指的是找到某条数据记录的方法；  

4.数据分片用以实现系统的水平扩展，数据复制用来保证数据的高可用性；  

5.主流的数据分片方法有：哈希分片和范围分片；哈希分片又主要有：RoundRobin、虚拟桶以及一致性哈希；  

6.**RoundRobin**：即哈希取模法。优点是实施起来简单，但是非常缺乏灵活性，新增机器需要全部重新调整；  

7.**虚拟桶**：在记录和物理机器之间加了中间层——虚拟桶层，即变成了记录——虚拟桶——物理机三层模型，记录和虚拟桶之间为多对一的关系，之间的key-partition映射采用hash函数，而虚拟桶——物理机之间也是多对一的关系，他们的关系使用表格管理；

8.**一致性哈希**：Consistent Hashing。一致性哈希基本解决了在P2P环境中最为关键的问题——如何在动态的网络拓扑中分布存储和路由。可以参见[每天进步一点点——五分钟理解一致性哈希算法(consistent hashing)](http://blog.csdn.net/cywosp/article/details/23397179); 为了解决一致性哈希中的机器负载不均衡问题，引入了**虚拟节点**；

9.**范围分片**：将所有记录的主键进行排序，然后将其进行数据分片，每个partition存储有序的主键空间片段内的所有记录。

## 第2章 数据复制与一致性
### 基本原则与设计理念
1.主要的基本原则有CAP、BASE以及ACID。这三者应用的场景各异。

2.**CAP**：大规模分布式集群系统的三大要素，但是三者不可兼得，这三者分别为：  
    C：consistency，强一致性。数据在多副本上的表现和在单一副本上是一样的；  
    A：availability，可用性。客户端的任何R/W操作都应该在限定延时内完成；   
    P：partition tolerance，分区容忍性。网络分区现象时，仍可以继续工作。  
 一般，在AP和CP之间选择。但是真实情况下，网络分区发生的概率低，因此，正常情况下，尽可能兼顾CAP三者。

3.**ACID原则**：这是关系型数据库库采用的原则，数据库系统通过采用ACID原则来保证系统的高可靠性和强一致性。  
	A：Atomicity，原子性。一个事务要么全部执行，要么全部不执行；   
	C：Consistency，一致性。事务在开始和结束时，应该始终满足一致性约束条件。如，系统满足A+B=100，那么事务如果改变了A，则B也要相应调整使得A+B=100仍然成立；  
	I：Isolation，事务独立性。是指多个事务同时执行的时候，他们彼此之间不需要知晓对方的存在以及状态。也就是说，事务之间需要序列化执行；  
	D：Durability，持久性。事务成功后，该事务对系统状态的更新是永久的；

4.**BASE**原则：大多数大数据环境下的云存储系统和NoSQL系统采纳的原则，强调可用性：   
	BA：Basically Available，基本可用。系统允许偶尔的失败，但是大部分时间都处于可用状态；  
	S：Soft State，柔性状态。数据状态不要求任意时刻都完全保持同步；  
	E：Eventual Consistency，最终一致性。要求在给定时间窗口数据会达到一致状态； 

	BASE原则和ACID原则不同，前者通过强一致性（最终一致性）获得高可用性。**NoSQL系统与云存储系统的发展正向着提供局部ACID特性发展，即从全局符合BASE原则，但是从局部支持ACID原则**。

5.分布式系统的幂等性：调用方反复执行同一操作与只正确执行一次操作结果相同。

6.一致性模型：严格上讲，真正的一致性只有我们所说的强一致性（又叫严格一致性）；一般地，一致性模型包括：强一致性、弱一致性、最终一致性、因果一致性、“读你所写”一致性、会话一致性、单调读一致性以及单调写一致性；

7.**强一致性**：当一个数据进行了更新操作后，所有后续的观察者都应该感知到这次数值变化并以此为基础进行后续的读写行为。所有不符合强一致性的行为都统称为弱一致性；

8.**最终一致性**：这是我们在分布式系统中常见的一种一致性模型，因为在分布式系统中，我们常常需要对数据进行备份来保证数据的高可用性。它属于弱一致性的范畴，最终一致性无法保证当某一数据发生更新操作后，所有后续操作能第一时间看到新的数据，而是需要经过一个时间片段（我们称之为“不一致窗口”）后才能保证这一点。  
不一致窗口取决于很多因素，比如备份数据的个数、网络延迟、系统负载大小等。

9.**因果一致性**：进程之间有因果依赖关心的情况下，当进程A将x的数值更新为v2时，会通过Notify(A,B,x,v2)来通知进程B数值已经进行了改变，然后进程B会以新数值为基础进行读写。  
但是，在进程A在通知进程B的过程中，仍然存在一个不一致窗口。

10.**“读你所写”一致性**：因果一致性的特例，进程A把数据x更新为v2后，立即给自己发一条Notify(A,A,x,v2)，所以进程A之后的操作都是以新数值v2作为基础。  

11.**单调读一致性**：最终一致性的一种变体。保证如果某个进程读取到数据x的某个版本数据v2，那么系统所有后续**读取操作**都不能看到比v2更老版本的数值；  

12.**单调写一致性**：也是最终一致性的一种变体。对于某个进程来说，单调写一致性可以**保证其多次写操作的序列化**。

13.副本更新策略：在多副本场景下，三种可能的副本更新策略：同时更新策略，主从式更新策略以及任意节点更新策略；

14.**同时更新策略**：一版有两种情形：
	1）不通过任何一致性协议同时更新多个副本数据。这种情况存在一个潜在的问题：假设同一时刻两个客户端对这个数据同时发出update操作，系统将无法确定先后顺序，即不同节点的更新顺序可能不一致；  
	2）通过某种一致性协议预先处理，一致性协议用来唯一确定不同更新操作的执行顺序，这样可以保证数据的一致性。但是请求延时会有所增加；

15.**主从式更新策略**：如果某数据的多副本中存在一个主副本（Master Replica），其他副本为从副本。所有对这个数据的更新操作首先提交到主副本，再由主副本通知从副本进行数据更新，并决定多个更新（如果存在）操作的顺序。根据主副本通知从副本的不同机制，存在以下3种类型：  
	1）同步方式：主副本等到所有从副本更新操作完成后才确认更新操作完成。这可以保证数据的强一致性，但是会存在较大的请求延时；  
	2）异步方式：主副本在通知从副本更新之前即可确认更新操作。但此时不能保证数据一致性。所以这种情况下，我们一般会先将这次更新操作记录下来并保存在另一个可靠的存储位置；  
	这种异步方式的请求延时和一致性之间的权衡取决于读操作的响应方式，又可以分为两种：  
	a.所有读请求都通过主副本来响应，即任意一个副本接到读请求都转发给主副本；可以保证数据的强一致性但是也会增加请求延时；  
	b.任意一个副本都可以响应读请求，这样请求延时将大大降低，但是不能保证数据的一致性；  
	3）混合方式：即主副本首先同步更新部分从副本数据，然后即可确认更新操作完成，其他副本通过异步方式获得更新。（Kafka在维护数据副本一致性时即采取此种混合方式）

16.**任意节点更新策略**：数据更新请求可能发给多副本的任意一个节点，然后由这个节点通知其他副本进行数据更新。

17.在实际的系统中，Dynamo/Cassandra/Riak同时采取了“主从式更新”的混合方式以及任意节点更新策略。在正常情况下，主从式更新的混合方式起作用，当主副本发生故障时，启用任意节点更新策略；
