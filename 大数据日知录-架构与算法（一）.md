# 大数据日知录-架构与算法（一）

## Intro
**声明：本系列文档为本人学习《大数据日知录 架构与算法》（张俊林著 电子工业出版社 2014年9月第一版）的内容提纲。**  
我幻想我有这样一个技能包，我在里面放了一些马上可以拿出来使用的技能，也放了一些技能的索引和说明，当我需要的时候我能想起它并且能快速找到它让其为我所用。


## 第0章 当谈论大数据时我们在谈什么
1.大数据处理的目标：从海量异质数据中挖掘知识。包含了数据源收集、数据存储管理、数据分析与挖掘以及数据展现与获取等。

## 第1章 数据分片与路由
1.纵向扩展：传统并行数据库系统为了获取更好的性能，通过改善单机硬件资源；  

2.横向扩展：目前主流的大数据存储与计算系统通过增加机器来获得水平扩展能力；  

3.数据分片是指在大数据存储中，将海量的数据切分然后分配到各个机器中去，而数据路由指的是找到某条数据记录的方法；  

4.数据分片用以实现系统的水平扩展，数据复制用来保证数据的高可用性；  

5.主流的数据分片方法有：哈希分片和范围分片；哈希分片又主要有：RoundRobin、虚拟桶以及一致性哈希；  

6.**RoundRobin**：即哈希取模法。优点是实施起来简单，但是非常缺乏灵活性，新增机器需要全部重新调整；  

7.**虚拟桶**：在记录和物理机器之间加了中间层——虚拟桶层，即变成了记录——虚拟桶——物理机三层模型，记录和虚拟桶之间为多对一的关系，之间的key-partition映射采用hash函数，而虚拟桶——物理机之间也是多对一的关系，他们的关系使用表格管理；

8.**一致性哈希**：Consistent Hashing。一致性哈希基本解决了在P2P环境中最为关键的问题——如何在动态的网络拓扑中分布存储和路由。可以参见[每天进步一点点——五分钟理解一致性哈希算法(consistent hashing)](http://blog.csdn.net/cywosp/article/details/23397179); 为了解决一致性哈希中的机器负载不均衡问题，引入了**虚拟节点**；

9.**范围分片**：将所有记录的主键进行排序，然后将其进行数据分片，每个partition存储有序的主键空间片段内的所有记录。

## 第2章 数据复制与一致性
### 基本原则与设计理念
1.主要的基本原则有CAP、BASE以及ACID。这三者应用的场景各异。

2.**CAP**：大规模分布式集群系统的三大要素，但是三者不可兼得，这三者分别为：  
    C：consistency，强一致性。数据在多副本上的表现和在单一副本上是一样的；  
    A：availability，可用性。客户端的任何R/W操作都应该在限定延时内完成；   
    P：partition tolerance，分区容忍性。网络分区现象时，仍可以继续工作。  
 一般，在AP和CP之间选择。但是真实情况下，网络分区发生的概率低，因此，正常情况下，尽可能兼顾CAP三者。
